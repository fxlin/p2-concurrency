{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Concurrency","text":"<pre><code>git clone https://github.com/fxlin/p2-concurrency\n</code></pre> <p>This project has two experiments. </p> <p>Clone the whole repository first. Follow the project description, tinker with the given benchmark program and reproduce the demo results. Finish the assignments. </p>"},{"location":"#work-with-the-server","title":"Work with the server","text":"<p> An overview figure. See details below. </p>"},{"location":"#prerequisite-connect-to-server","title":"Prerequisite: connect to server","text":"<p>This experiment should be finished on granger1/2. Unlike p1, the programs here can be CPU intensive. Be mindful about the server load. </p> <p>Use granger2 if granger1 is heavily loaded. </p>"},{"location":"#adventurous-use-your-local-machine-instead-of-granger12","title":"(Adventurous) Use your local machine instead of granger1/2?","text":""},{"location":"#linux","title":"Linux","text":"<p>Make sure your machine has more than a dozen of cores (e.g. Ryzen 9, Threadripper, some Intel i9). Recommended OS: Ubuntu 20.04. Other Linux distros should work as well. </p> <pre><code>sudo apt install build-essential\nsudo apt install cmake gcc gcc-aarch64-linux-gnu \n# python for plotting\nsudo apt install python3 python3-pip\npip3 install bokeh\n# for exercises\nsudo apt install libglib2.0-dev\n</code></pre>"},{"location":"#windows","title":"Windows","text":"<p>Native compilation possible with MINGW-64. </p> <p>WSL not recommended -- it may have scalability bottleneck. </p>"},{"location":"#build-the-given-code","title":"Build the given code","text":"<p>Follow the CMake instructions. </p>"},{"location":"#set-up-profilertracer","title":"Set up profiler/tracer","text":"<ul> <li> <p>Follow the instructions on Intel VTune</p> </li> <li> <p>A simple tracing library </p> </li> </ul>"},{"location":"#experiments","title":"Experiments","text":"<ul> <li>Exp1: Races &amp; Synchronization </li> <li> <p>Description </p> </li> <li> <p>Exp2: Scalability </p> </li> <li>Description </li> </ul> <p>Credits: inspired by UCLA \"Operating Systems Principles\"</p>"},{"location":"cmake/","title":"Build the benchmark with CMake","text":""},{"location":"cmake/#background","title":"Background","text":"<p>Our source tree is managed by <code>CMake</code> instead of a hand-written Makefile. CMake is widely used to build large codebases. To us, CMake eases building multiple versions of the same source code, each built with difference build flags. We will see the benefits in subsequent experiments. </p> <p>To use CMake, we list our build targets in a file called <code>CMakeLists.txt</code>. Then we invoke <code>cmake</code>, which will take <code>CMakeLists.txt</code> and  generate a <code>makefile</code> . <code>cmake</code> will then invoke make automatically. </p>"},{"location":"cmake/#first-time-build","title":"First time build","text":"<pre><code>git clone https://github.com/fxlin/p2-concurrency\n# assuming we are building exp1\n$ cd exp1\n$ cmake .\n</code></pre> <p>This generates a Makefile from CMakeLists.txt. Then type:</p> <pre><code>$ make\n</code></pre> <p>Troubleshooting if CMakeCache.txt is complained to be out of date, simply delete or rename it and run <code>cmake</code> again. </p> <p>Peek at the generated Makefile to see whether you can understand it. </p>"},{"location":"cmake/#each-time-you-modify-source-and-need-to-rebuild","title":"Each time you modify source and need to rebuild","text":"<p>Simply run: <code>make</code></p> <p>To build individual targets: </p> <pre><code>$ make &lt;tab&gt; &lt;tab&gt; # this will list all targets\n# examples: \n$ make counter\n$ make clean\n</code></pre> <p>To see what commands are actually invoked by Make, do </p> <p><code>$ make VERBOSE=1</code></p>"},{"location":"cmake/#optional-cross-build-for-aarch64","title":"Optional: cross-build for aarch64","text":"<p>Clean up all cmake intermediate files: </p> <pre><code>$ rm -rf CMakeCache.txt  CMakeFiles  cmake_install.cmake\n</code></pre> <p>Then invoke cmake to regenerate for aarch64: </p> <pre><code>$ cmake . -DCMAKE_ENV=aarch64\n</code></pre> <p>Build everything: </p> <pre><code>$ make\n</code></pre> <p>Check the resultant binaries, which should show \"ARM aarch64\"</p> <pre><code>$ file counter\ncounter: ELF 64-bit LSB shared object, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.7.0, BuildID[sha1]=f258ebadfacd9e41bc0425c6446ae419278fb50e, with debug_info, not stripped\n</code></pre> <p>Now you can disassemble the ARM64 program with <code>aarch64-linux-gnu-objdump</code>. e.g.</p> <pre><code>$ aarch64-linux-gnu-objdump -dS counter | more\ncounter:     file format elf64-littleaarch64\n\nDisassembly of section .init:\n\n0000000000000f90 &lt;_init&gt;:\n f90:   a9bf7bfd        stp     x29, x30, [sp, #-16]!\n f94:   910003fd        mov     x29, sp\n f98:   94000137        bl      1474 &lt;call_weak_fn&gt;\n f9c:   a8c17bfd        ldp     x29, x30, [sp], #16\n fa0:   d65f03c0        ret\n\nDisassembly of section .plt:\n\n0000000000000fb0 &lt;.plt&gt;:\n     fb0:       a9bf7bf0        stp     x16, x30, [sp, #-16]!\n     fb4:       b0000090        adrp    x16, 11000 &lt;__FRAME_END__+0xf658&gt;\n     fb8:       f9478211        ldr     x17, [x16, #3840]\n     fbc:       913c0210        add     x16, x16, #0xf00\n     fc0:       d61f0220        br      x17\n     fc4:       d503201f        nop\n     fc8:       d503201f        nop\n     fcc:       d503201f        nop\n&lt; ... &gt;     \n</code></pre>"},{"location":"exp1/","title":"Races and Synchronization","text":"<pre><code># git clone https://github.com/fxlin/p2-concurrency\ncd p2-concurrency/exp1/\n</code></pre> <p>To build the given code, see here.</p>"},{"location":"exp1/#objectives","title":"Objectives","text":"<p>We will tinker with a minimalist, multithreaded app and see the role of synchronization. </p>"},{"location":"exp1/#student-experience","title":"Student experience","text":"<ul> <li>primary: recognize critical sections and protect them with a variety of mechanisms.</li> <li>primary: demonstrate race conditions and how to fix them </li> <li>primary: experience with performance instrumentation, measurement and analysis</li> </ul> <p>This experiment focuses less on programming, and more on performance measurement and analysis.</p> <p>We will focus on concurrency correctness in this experiment, and will consider scalability in the subsequent experiment. </p>"},{"location":"exp1/#prerequisites","title":"Prerequisites","text":"<p>To do this experiment, you may need to study a few things:</p> <ul> <li> <p>a more complete tutorial on pthreads. Our benchmark app is written in the <code>pthread</code> API.</p> </li> <li> <p>clock_gettime(2) ... high resolution timers (for accurate performance data collection).</p> </li> <li> <p>GCC atomic builtins ... functions to directly execute atomic read-modify-write operations.</p> </li> </ul>"},{"location":"exp1/#benchmark-counterc-a-shared-integer-counter","title":"Benchmark (counter.c): a shared integer counter","text":"<p>Our benchmark program uses multiple threads to update a shared integer counter in parallel. The source project is built via CMake. See our short introduction on CMake here.</p> <p>The program defines a global variable: </p> <pre><code>long the_counter = 0;\n</code></pre> <p>The main function spawns N worker threads and then waits for them to join: </p> <pre><code>pthread_t threads[numThreads];\n\nfor (int i = 0; i &lt; numThreads; i++) {\n    if (pthread_create(&amp;threads[i], NULL,\n                       (void*) &amp;thread_func, &amp;iterations) &lt; 0) {\n        perror(\"thread_create:\");\n        exit(1);\n    }\n}\n\nfor (int i = 0; i &lt; numThreads; i++) {\n    if (pthread_join(threads[i], NULL) &lt; 0) {\n        perror(\"thread_join\");\n        exit(1);\n    }\n}\n</code></pre> <p>Each thread runs the following function to flip the shared counter repeatedly: </p> <pre><code>void thread_func(int *iterations) {\n    for (int i = 0; i &lt; *iterations; i++)\n        add(&amp;the_counter, 1);\n\n    for (int i = 0; i &lt; *iterations; i++)\n        add(&amp;the_counter, -1);\n}\n</code></pre> <p>The function <code>add</code> updates the global counter value by adding a value to it: </p> <pre><code>void add(long long *pointer, long long value) {\n    long long sum = *pointer + value;\n    *pointer = sum;\n} \n</code></pre> <p>Note that <code>value</code> is signed, meaning that <code>add()</code> can either increment or decrement the counter. </p>"},{"location":"exp1/#observation","title":"Observation","text":"<p>After all the worker threads are joined, what would be the final value for <code>the_counter</code>? Should it be zero, since the counter is incremented &amp; decremented the same number of times? </p> <p>The problem is race condition: multiple worker threads update the counter without mutual exclusion. How bad could it be? </p>"},{"location":"exp1/#concurrent-update-wo-locking","title":"Concurrent update w/o locking","text":"<p>We may see <code>the_counter==0</code> after workers are joined -- with a few threads and fewer iterations</p> <pre><code>$./counter-nolock --iterations=100 --threads=10\ntest=add-none threadNum=10 iterations=100 numOperation=2000 runTime(ns)=634688 avgTime(ns)=317 count=0\n</code></pre> <p>However, as the numbers of threads/iterations increase moderately, we will soon observe a non-zero <code>the_counter</code> -- there's an error in our program! </p> <pre><code>$./counter-nolock --iterations=10000 --threads=10\ntest=add-none threadNum=10 iterations=10000 numOperation=200000 runTime(ns)=5280826 avgTime(ns)=26 count=-5275\n</code></pre> <p>Why does a smaller number of iterations rarely fail?  Why does it take more iterations before errors are seen?  </p>"},{"location":"exp1/#concurrent-update-with-locking","title":"Concurrent update with locking","text":"<p>Of course, one way to fix the race condition is to wrap <code>add()</code> with locking: </p> <pre><code>// create a global mutex\npthread_mutex_t mutex;\npthread_mutex_init(&amp;mutex, NULL)\n\n// in each worker thread\npthread_mutex_lock(&amp;mutex);\nadd(&amp;the_counter, val);\npthread_mutex_unlock(&amp;mutex);\n</code></pre> <p>With synchronized updates, we will always see the right count value: </p> <pre><code>$ ./counter --iterations=100000 --threads=10 --sync=m\ntest=add-m threadNum=10 iterations=100000 numOperation=2000000 runTime(ns)=147502381 avgTime(ns)=73 count=0\n</code></pre>"},{"location":"exp1/#conclusion","title":"Conclusion","text":"<p>We have seen the necessity of synchronization and understood the basic structure of the benchmark. Play with the given benchmark and reproduce the results above. After that, proceed to the assignments.</p>"},{"location":"exp2/","title":"Scalability","text":"<p>In the previous experiment, synchronization prevents racy access to a shared variable. In this experiment, we will study the overhead of synchronization, as well as how to overcome the resultant bottleneck.  </p>"},{"location":"exp2/#objectives","title":"Objectives","text":"<ul> <li>primary: demonstrate the ability to recognize scalability bottlenecks on data structures</li> <li>primary: experience with partitioning a serialized resource to improve parallelism</li> <li>primary: know that scalability takes a system approach and is often not as easy as one may think.</li> <li>primary: experience with a modern profiler </li> <li>secondary: experience with finding, installing, and exploiting new libraries and tools. </li> </ul>"},{"location":"exp2/#the-benchmark","title":"The benchmark","text":"<p>We will study a simple program (list.c) that inserts 64-bit integer keys into a doubly linked list. The figure below illustrates the execution timeline. </p> <p></p> <ul> <li>in the init phase, one thread pre-generates keys and stores them in a table in memory</li> <li>in the parallel phase, multiple threads read keys from the table and insert them to a shared linked list</li> <li>the keys can be unsorted in the table, and can be unsored in the linked list</li> </ul> <p>This benchmark is for educational purpose. The reason we use a linked list is for simplicity. A more useful concurrent data structure would be hashtable, which we will see in the exercise. </p>"},{"location":"exp2/#measuring-performance","title":"Measuring performance","text":""},{"location":"exp2/#metrics","title":"Metrics","text":"<p>We care about two metrics: </p> <ol> <li>the program's overall performance, which is characterized by its aggregate throughput, i.e. key insertions per second by all threads combined. </li> <li>scalability: how much the throughput increases as we use more threads (cores) in  the program. </li> </ol>"},{"location":"exp2/#methodologies","title":"Methodologies","text":"<p>We have to run our benchmark for sufficiently long (more than a few seconds). Otherwise, the measurement will be distorted by the startup cost (cache warmup, kernel scheduling, etc.) and sampling errors (e.g. VTune samples context switches at millisecond intervals). </p> <p>How to measure throughput?  We will instrument the benchmark source code with clock_gettime(), before and after the parallel phase, to measure <code>time_diff</code>.  This is shown in the figure above. Our measurement focuses on the parallel phase, and excludes the time of init phase (e.g. key generation) from measurement. </p> <p>Q: before we measure anything, make an educated guess of the throughput ballpark. </p> <p>The scalability plot</p> <p>With the same number of iterations (i.e. total number of keys to insert by each thread), we run the benchmark with different numbers of threads. Each run will report its throughput, e.g. </p> <pre><code>$./list --iterations=1M --threads=1 \n..\ntest=list-none threadNum=1 iterations=1000000 numList=1 numOperation=1000000 runTime(ms)=115 tput(Mops)=8.63\n$./list --iterations=1M --threads=2\n..\n</code></pre> <p>To automate the test, we provide a boilerplate script called <code>run.sh</code>, which launches the benchmark in multiple runs. For each run, the script redirects the program's output (both stdout and stderr) to a txt file. </p> <pre><code># see run.sh for more details\nfor tr in 1 2 4 8 \ndo \n    $VTUNE $PROG --iterations=$ITER  --threads=$tr --lists=`expr $tr \\* $FACTOR` &gt;&gt; $TRACEFILE 2&gt;&amp;1   \ndone\n</code></pre> <p>You need to understand <code>run.sh</code> and make your adjustment. </p> <p>FYI -- A Python script <code>scripts/plot.py</code> parses multiple such txt files from a set of runs and produces a scalability plot. All plots below are generated by the Python script. Feel free to use &amp; adapt <code>plot.py</code>.  Check out its comments for details. </p> <p>All following experiments are done with the following parameters: 1M keys (iterations) per thread, 1-8 threads. </p>"},{"location":"exp2/#the-source-code-structure","title":"The source code structure","text":"<p>We maintain one copy of source code with all the fixes (or \"features\") needed for scalability. These fixes can be turned on/off at the compile time, controlled via a set of compilation flags in C. When we type <code>make</code>, our makefile (generated by CMake) will build the same source code with different combinations of compilation flags, producing a series program binaries with different fixes on or off. </p> <p>In the discussion below, we start with all fixes off, incrementally turn on fixes, and show the resultant scalability. You will see why each fix matters and to what extent it matters. </p> <p>FYI -- here is a list of all the program versions we will examine. </p> Program name suffix (\"list-XXX\") list(s) memory allocation load balancing eliminating false sharing N/A, aka \"biglock\" One big list malloc() No No -p Partitioned lists malloc() No No -pm Partitioned lists pre-allocated No No -pml Partitioned lists pre-allocated Yes No -pmla Partitioned lists pre-allocated Yes Yes"},{"location":"exp2/#the-baseline-biglock","title":"The baseline (\"biglock\")","text":"<p>In the first version, multiple threads insert pre-generated keys to a monolithic list. Partitioning the keys for threads to insert is easy: we split the the array in as many ranges as the worker threads, and make each worker thread work on a range of keys. To avoid corrupting the list, we need one lock for the whole list. Each thread must grab the lock before inserting any key.  The design is shown below. </p> <p></p> <p>The core function is: </p> <pre><code>// list.c built without any macro defined\nvoid* thread_func(void *thread_id) {\n    /* ... */\n    int id = *((int*)thread_id);\n    int per_part = numElements / the_config.numParts; // numParts == numThreads\n\n    for (int i = per_part * id; i &lt; per_part * (id + 1); i++) {\n            // we carefully do malloc() w/o grabbing lock\n            SortedListElement_t *p = get_element(i);\n\n            pthread_mutex_lock(&amp;mutexes[0]); // only one mutex and one list\n            SortedList_insert(&amp;lists[0], p);\n            pthread_mutex_unlock(&amp;mutexes[0]);\n     }  \n     /* ... */\n}   \n</code></pre> <p>In the code above, <code>get_element()</code> allocates a new list node and copies over a key from the array index <code>i</code>. The code is: </p> <pre><code>SortedListElement_t *get_element(int idx) {\n    SortedListElement_t *p = malloc(sizeof(SortedListElement_t));\n    p-&gt;key = keys[idx];\n    return p;\n}   \n</code></pre> <p>Results. Type <code>make</code>, we get a program called <code>list</code>. Run <code>list</code> multiple times with different core counts (see the \"scalability plot\" paragraph above), we get a scalability plot. </p> <p></p> <p>Why does not it scale? You probably have figured out the reason. Essentially, the insertion becomes a critical section. All worker threads are serialized on this critical section. While one worker thread is in, all other threads must wait outside doing nothing. Here is a sample profiling result from VTune: </p> <p></p> <p>On the top, the profiling result shows that mutex lock/unlock contribute a high fraction of \"spin time\". The timeline on the bottom shows that all worker threads are spinning frequently (the orange portions) without doing much useful work (the brownish portions). </p> <p>But this does NOT explain why throughput drops as thread counts goes up, right? </p>"},{"location":"exp2/#attempt-1-remove-the-big-lock-by-partitioning-list-p","title":"Attempt 1: remove the big lock by partitioning (\"list-p\")","text":"<p>Realizing the problem is the monolithic linked list, why don't we partition it? We can make each worker thread insert to its own list. After all keys are inserted and all worker threads are joined, the main thread simply concatenates the per-worker lists to a big one. Since we do not require the final list to be sorted, the concatenation takes O (1). The design is shown below. </p> <p></p> <p>We quickly change the core code as follows, which no longer needs the big lock: </p> <pre><code>// list.c compiled with -DMULTILISTS\nSortedList_t* lists = malloc(sizeof(SortedList_t) * the_config.numThreads); \n\nvoid* thread_func(void *thread_id) {\n    /* ... */\n    int id = *((int*)thread_id);\n    int per_part = numElements / the_config.numThreads;\n\n    for (int i = per_part * id; i &lt; per_part * (id + 1); i++) \n        SortedList_insert(&amp;lists[id], get_element(i));    \n    /* ... */\n}   \n</code></pre> <p>Results. Run <code>make</code>, we get a binary called <code>list-m</code> which includes the above feature by <code>-DMULTILISTS</code>. </p> <p>Removing the lock helps quite a lot! However, we are still not scaling ideally. :dizzy_face:</p> <p></p>"},{"location":"exp2/#attempt-2-avoid-expensive-memory-allocation-list-pm","title":"Attempt 2: avoid expensive memory allocation (\"list-pm\")","text":"<p>The problem. The profiling result of <code>list-m</code> shows that <code>malloc()</code> is the top hotspot, taking more than 50% of the total CPU time. This sounds right: our thread workers calls <code>malloc()</code> at high rates, and <code>malloc()</code> has scaling bottleneck in itself. </p> <p>The second hottest item is [vmlinux] which is the kernel. Why is our benchmark kernel-intensive? </p> <p></p> <p>The fix. You may try \"scalable memory allocators\", such as jemalloc, Hoard, and the one from Intel's TBB. Thanks to years of R&amp;D on scalable allocation, these allocators for sure will scale better than the good and old <code>malloc</code>. However, our microbenchmark, where many threads allocate small memory pieces in tight loops, is probably too adversarial and can defeat them easily. </p> <p>The right way to fix? The spirit is to aggressively specialize memory allocation according to our workloads Have a memory pool populated with many pre-allocated same-size list nodes. Whenever a worker thread requests a new node, it can quickly grab a free node from the pool; the pool is designed in a way such that most allocation/free requests can be fulfilled without locking the whole pool. This is also the idea behind the Linux kernel's slab allocator.</p> <p>As compared to generic, complex memory allocators, specialization gives us simplicity, and therefore low cost and scalability. </p> <p>However, designing a scalable memory pool is easier saying than doing. There are many details to take care of. Without too much distraction into it, we fix our memory allocation problem by \"emulating\" the effect of such a memory pool. The main thread pre-allocates all list nodes in one big memory chunk by one <code>malloc()</code> in the init phase. This simplistic mechanism has many limitations, e.g. cannot free nodes individually but has to free all nodes as a whole. But you get the idea. </p> <p>Can you try jemalloc on the benchmark? </p> <p>We pre-allocate a big an array of list nodes in <code>main()</code>, and change the way thread workers get elements: </p> <pre><code>// list.c compiled with -DUSE_PREALLOC\nSortedListElement_t *alloc_elements(int numElements) {\n    /* ... */\n    SortedListElement_t * elements = malloc(sizeof(SortedListElement_t) * numElements);\n    /* ... */\n}\n\nSortedListElement_t *get_element(int idx) {\n    return &amp;elements[idx];\n}\n</code></pre> <p></p> <p>The results. Run <code>make</code> to produce a binary called <code>list-pm</code>, which includes the above features with flags <code>\"-DUSE_PREALLOC -DUSE_MULTILISTS\"</code>.  </p> <p>Viola! Our throughput (\"nomalloc\") is 4x-5x better without expensive malloc() in worker threads. But it still scales poorly. </p>"},{"location":"exp2/#attempt-3-eliminate-stragglers-list-pml","title":"Attempt 3: eliminate stragglers (\"list-pml\")","text":"<p>The problem. It's time to summon VTune again. Look at the threading timeline closely: we notice that all worker threads can proceed at different rates. Although they i) insert the same number of keys and ii) start more or less at the same time (near 1000ms), they take very different times to complete! The difference could be as high as 3x! The slower workers (called \"straggler\", e.g. the ones on the bottom) become the bottleneck, as the main thread has to wait for all workers to complete.  </p> <p>Now, the more worker threads we have, the more likely we have stragglers, and the worse the problem is! This limits scalability. </p> <p>Stragglers are a generic performance issue, e.g. when you run distributed workloads across multiple machines within a data center. </p> <p>Note: on the timeline below, our instrumentation with VTune's ITT API is visible -- we declared multiple per-thread \"tasks\" which emerge as the colorful brackets above each thread's timeline. This feature is enabled by -DUSE_VTUNE. </p> <p></p> <p>Why stragglers exist? Our target machine has abundant CPU cores (20), many of them are still idle in this experiment which uses 8 cores. There are multiple causes. 1) Nondeterminism exists everywhere in commodity software/hardware, from memory bus to the kernel CPU scheduler. 2) Our workers compete for shared hardware resources -- among themselves and with other tasks in the system. </p> <p>After all, our program has to accommodate the fact that threads may proceed at quite different rates!</p> <p>The fix. Our problem is that we assign the same amount of work to every worker (i.e. the same number of keys). Instead, we should dynamically adjust the amount of work for workers depending on their progresses. </p> <p>We achieve this by slicing the input key array into smaller parts, where the number of parts, e.g. 64,  is much higher than the number of worker threads, e.g. 8. In the parallel phase, each worker will try to grab a part to work on. We put an atomic flag for each part, whichever worker grabs it will set the flag so that other workers can skip this part. </p> <p></p> <p>Accordingly, we upgrade the code for worker thread: </p> <pre><code>void* thread_func(void* thread_id) {\n    /* ... */\n    for (int part = 0; part &lt; the_config.numParts; part++) { // go through all parts of keys\n        if (__sync_lock_test_and_set(&amp;spinLocks[part], 1) == 0) { // try to grab a part of keys to work on\n            for (int i = per_part * part; i &lt; per_part * (part + 1); i++)       { // we've got a part!\n                SortedList_insert(&amp;lists[id], get_element(i));\n            }\n    }\n    /* ... */\n}\n</code></pre> <p>Some rationale behind determining the size of each part (and hence how many parts). </p> <ul> <li>Each part has to be sufficiently small so that workload is evenly balanced across workers. </li> <li>Each part cannot be too small otherwise the overhead from grabbing parts (e.g. setting atomic flags) will start to emerge. </li> </ul> <p>Often, # of parts = 4x # of numThreads is enough to diminish stragglers.</p> <p>The results. Run <code>make</code> to produce <code>list-pml</code>, which includes the above features with flags <code>\"-DUSE_PREALLOC -DUSE_LB\"</code>.  Run VTune again. </p> <p>Hooray! Now all workers end more or less at the same time, indicating our fix is effective. Note the colorful brackets in the figure below. Each bracket corresponds to a worker working on one part of keys. it's fun to watch how our workers share workloads dynamically. In this example, fast workers can finish 5 parts while slower workers can only finish 3. As we have more worker threads and more parts, the effect will be more pronounced!</p> <p></p> <p>After load balancing, our scalability plot looks as the following. It's notably better (especially for a larger number of threads) but still not ideal. Why?</p> <p></p>"},{"location":"exp2/#attempt-4-remove-false-sharing-list-pmla","title":"Attempt 4: remove false sharing (\"list-pmla\")","text":"<p>The problem. Compare the run with ONE worker and the run with TWO workers. (The output is produced by using our lightweight, in-house tracing functions) You will see both workers in the second run takes much longer time (\"tr done\", 360ms+ vs 271ms) than the single worker in the first run. </p> <pre><code>./list-pml --iterations=10M --threads=1\n--------------------k2_measure_flush------#samples=6---------------\n                                     msg   delta(tod/us)        now(tod)\n*                                    init               0      3186721656\n                                init done           32166      3186753822\n                              tr launched              52      3186753874\n                                 tr start              44      3186753918\n                                  tr done          271050      3187024968\n                                tr joined             116      3187025084\n TOTAL: 303428 us(gettimeofday)  tracebuf overflow: 0\n---------------------------------------------------------------\n\n./list-pml --iterations=10M --threads=2\n--------------------k2_measure_flush------#samples=8---------------\n                                     msg   delta(tod/us)        now(tod)\n*                                    init               0      3378084426\n                                init done           33455      3378117881\n                              tr launched              93      3378117974\n                                 tr start               3      3378117977\n                                 tr start              42      3378118019\n                                  tr done          360317      3378478336\n                                  tr done           18851      3378497187\n                                tr joined             112      3378497299\n TOTAL: 412873 us(gettimeofday)  tracebuf overflow: 0\n---------------------------------------------------------------\n</code></pre> <p>In the second run, the two workers seem to slow down each other. However, by design, we intent these two workers to be independent without sharing anything such as locks. How could this happen? </p> <p>It turns our that they indeed share something, albeit implicitly. </p> <p>Recall that we allocate the heads of per-worker lists back to back with the following code: </p> <pre><code>SortedList_t * alloc_lists(int n_lists) {\n    /* ... */\n    lists = malloc(sizeof(SortedList_t) * the_config.numThreads);\n    /* ... */\n}   \n</code></pre> <p>Each list head is only as small as tens of bytes. Therefore, multiple adjacent list heads fit into the same CPU L1 cache line. As each worker inserts nodes by updating its own list head frequently, a cache line could be bumping among different CPU cores these workers run on; this causes a lot of core-to-core traffic and causes performance degradation. </p> <p>You may have learnt from the architecture course: this is called false sharing. To refresh your memory, read about it here and the first several slides of this deck. </p> <p>There are multiple mechanisms to remove false sharing, e.g. percpu variables in Linux. The common idea is placing those memory objects far apart so that they won't be mapped to the same CPU cache line. In this experiment, we achieve so by manual padding.  We enlarge a list head by enclosing extra bytes at its end. </p> <pre><code>struct SortedListElement_padding {\n  struct SortedListElement *prev;\n  struct SortedListElement *next;\n  my_key_t key;\n  char padding[4096];\n};\n</code></pre> <p>As a result, we push the fields (<code>prev</code> and <code>next</code>) that are frequently updated to separate CPU cache lines. </p> <p></p> <p>The results. Run <code>make</code> to produce a binary called <code>list-pmla</code>, which includes all the above features with flags <code>\"-DUSE_PREALLOC -DUSE_LB -DUSE_PADDING\"</code>.  After this change, we are much close to linear scaling! :happy:</p> <p></p>"},{"location":"exp2/#conclusion","title":"Conclusion","text":"<p>Now you should have basic knowledge on scalability concepts, the tools, and some common pitfalls. </p>"},{"location":"measurement/","title":"A simple tracing facility in C","text":"<p>I have a small tracing library (measure.[c|h]) that I used quite a lot. Being simple, it has a few advantages: </p> <ul> <li>Easy to integrate. Minimal external dependency. Only one single C file. </li> <li>Simple APIs. Only three functions. </li> <li>Low overhead. No dynamic memory allocation (a static tracebuffer); no string manipulation; no IO until trace collection completes. </li> </ul>"},{"location":"measurement/#to-integrate","title":"To integrate","text":"<pre><code>// in .C \n#include \"measure.h\"\n// in Makefile\nOBJ += measure.o\n</code></pre>"},{"location":"measurement/#api","title":"API","text":"<ul> <li>k2_measure(const char *) emit a tracepoint to the tracebuffer. </li> <li>k2_measure_flush() print out all tracepoints in the tracebuffer and clear the buffer</li> </ul> <p>Not thread-safe. Must be locked in a multithreaded environment.</p> <p>Example:</p> <pre><code>k2_measure(\"start\");\n    for (int i = 0; i &lt; 2; i++) {\n        sleep(1);\n        k2_measure(\"slept 1sec\");\n    }\nk2_measure_flush();\n</code></pre>"},{"location":"measurement/#output","title":"Output","text":"<p>From the above code example: </p> <pre><code>--------------------k2_measure_flush------#samples=3---------------\n                                     msg   delta(tod/us)        now(tod)\n*                                   start               0      3155758523\n                               slept 1sec         1000079      3156758602\n                               slept 1sec         1000084      3157758686\n TOTAL: 2000163 us(gettimeofday)  tracebuf overflow: 0\n---------------------------------------------------------------\n</code></pre> <p>Columns</p> <ul> <li>\"msg\": the tag string included in k2_measure() call. </li> <li>\"delta\": the time difference (in microseconds) as compared to the previous tracepoint. Useful for measuring the time taken in one code region. </li> <li>\"now\": the absolute timestamps, in microseconds. </li> </ul>"},{"location":"vtune-cmd/","title":"VTune command line results viewer","text":""},{"location":"vtune-cmd/#this-doc-is-about-viewer-on-the-linux-command-line-not-the-profiler","title":"This doc is about VIEWER on the Linux command line, not the PROFILER.","text":"<p>For those who are struggling with MacOS... Do this from granger1/2 in order to view profiling results. </p> <p>Quite primitive but may be useful.\u00a0</p>"},{"location":"vtune-cmd/#generating-a-report","title":"Generating a Report","text":"<p>You can also use the\u00a0vtune\u00a0command with the\u00a0-report\u00a0option to generate a report. There are several ways to group data in a report, as follows:</p> <p>To report time grouped by functions (in descending order) and print the results to\u00a0stdout, or to a specific output text file, such as\u00a0output.txt:</p> <pre><code>vtune -report hotspots -r r000hs\n</code></pre> <p>or</p> <pre><code>vtune -report hotspots -r r000hs -report-output output\n</code></pre> <p>To report time grouped by source lines, in descending order:</p> <pre><code>vtune -report hotspots -r r000hs -group-by source-line\n</code></pre> <p>To report time grouped by module:</p> <pre><code>vtune -report hotspots -r r000hs -group-by module\n</code></pre>"},{"location":"vtune-cmd/#reference","title":"Reference:","text":"<p>https://www.nas.nasa.gov/hecc/support/kb/finding-hotspots-in-your-code-with-the-intel-vtune-command-line-interface_506.html</p>"},{"location":"vtune/","title":"Using Intel VTune, the modern x86 profiler","text":"<p>This page describes VTune setup relevant to our experiments. It contains pointers to various information. </p>"},{"location":"vtune/#why-vtune","title":"Why VTune","text":"<p>For performance debugging like this, our \"roll-it-your-own\" manual code instrumentation can be too rudimentary. Modern profilers have been crucial. In short, programmer launches a tool (\"profiler\") which in turns launches the target program to be profiled. The profiler collects key information about target program execution, and presents the results to developers for post-analysis.</p> <p>Over the past decade, profiling has seen tremendous improvement, evolving from software-based instrumentation to hardware-assisted sampling. Today, profilers can have very low overhead. </p>"},{"location":"vtune/#naming","title":"Naming","text":"<p>VTune is Intel's profiler. Prior to 2018 it was called Intel \"VTune Amplifier\" (a marketing term). There are still some old documents online with the latter name. Many of the current VTune executables are still named with the \"amplxe-\" prefix. Today it is called \"oneAPI VTune\". </p>"},{"location":"vtune/#vtune-documents","title":"VTune documents","text":"<p>VTune's front page feature short articles &amp; videos. Recommended readings: </p> <ul> <li>A quick introduction. This video (7 min)</li> <li>A case study on profiling Linux program. This video (4.5min)</li> <li>About CPU instruction pipeline: this video and this article . A good refresher on CPU architecture and for understanding architecture profiling results. </li> </ul> <p>There are more and you may skim them.</p> <p>The official user guide is here. It's long and you do NOT have to read from back to end. Just make sure when you Google/Bing (e.g. \"vtune threading profiling\"), ONLY pick results coming from this user guide. </p>"},{"location":"vtune/#step-0-setup","title":"Step 0. Setup","text":"<p>In our experiments, we run and profile our program on the server machine and view profile results on your local machine (Windows/Linux/Mac) from a browser.</p> <p>First, add VTune to the executable path: </p> <pre><code>source /opt/intel/vtune_profiler/vtune-vars.sh\nexport INTEL_LIBITTNOTIFY64=/opt/intel/vtune_profiler/lib64/runtime/libittnotify_collector.so\n</code></pre> <p>Do this every time you login to the server. Or you can simply do \"source env-vtune.sh\" (a script provided to you). </p> <p>Verify that vtune can be found: </p> <pre><code>$ which vtune\n/opt/intel/vtune_profiler_2020.2.0.610396/bin64/vtune\n$ which vtune-backend\n/opt/intel/vtune_profiler_2020.2.0.610396/bin64/vtune-backend\n</code></pre> <p>Reference </p>"},{"location":"vtune/#step-1-trace-collection","title":"Step 1. Trace collection","text":"<p>Develop code on the server remotely (e.g. via VS code). Write code -&gt; build binary -&gt; (test to make sure it works correctly). </p> <p>Next, profile the program with VTune. To do so, from the server command line: </p>"},{"location":"vtune/#example-commands-to-execute-for-each-collection","title":"Example commands, to execute for each collection","text":"<pre><code># hotspot analysis\nvtune -collect hotspot -knob sampling-mode=hw ./myprogram\n\n# threading analysis\nvtune -collect threading -knob sampling-and-waits=hw ./myprogram\n\n# microarchitecture analysis\nvtune -collect uarch-exploration ./myprogram\n\n# sample command to profile the assignment program\nvtune -collect hotspot -knob sampling-mode=hw ./list-p --iterations=100M --threads=1 --parts=1\n</code></pre> <p>(<code>-collect hotspot</code> seems the same as <code>-collect hotspots</code>)</p>"},{"location":"vtune/#where-are-the-profiling-results","title":"Where are the profiling results?","text":"<p>They are stored in a subdirectory automatically named as, e.g. \"r000tr/\", \"r014ue/\", \"r027hs/\". </p> <p>The numbers are assigned by VTune in an ascending manner. The last two letters are the analysis type. tr-\"threading\", ue-\"microarchitecture exploration\", \"hs\"-hotspot. </p>"},{"location":"vtune/#step-2-launch-vtune-backend-webserver","title":"Step 2. Launch vtune-backend (webserver)","text":"<p>We will launch \"vtune-backend'' on the server, which will present the profiling results over web UI: </p> <pre><code># Use a random port (recommended)\nvtune-backend --data-directory &lt;your directory&gt; \n\n# Use a specific port, run \"source env-tune.sh\" before below \nvtune-backend --web-port ${MYPORT} --data-directory &lt;your directory&gt;\n</code></pre> <p>For , you need to put the parent location where your results are located. For instance, if your results are located in <code>/u/bfr4xr/p2-concurrency/exp2/r000hs</code>, then  should be <code>--data-directory /u/bfr4xr/p2-concurrency/exp2</code>. If you successfully launch vtune-backend, you will see similar lines like below:  <p>In this case, the port number is <code>38881</code>. </p>"},{"location":"vtune/#step-3-view-trace-from-a-local-browser","title":"Step 3. View trace from a local browser","text":"<p>Make another SSH connection (from your local machine to the server) with the port from the output above, e.g. </p> <pre><code># From your local machine (Windows: PowerShell/VSCode; Mac: Terminal)\nssh -L 38881:127.0.0.1:38881 bfr4xr@granger2.cs.virginia.edu\n# NOTE: 38881 is just an example; use your own port\n</code></pre> <p>This technique is called SSH Tunneling, which maps the server's 38881 port to your local machine's 38881 port. As a result, it transports data from the remote server to the local server. See this for more. </p> <p>Note: You need two SSH connections with this task: one launches \"vtune\" and \"vtune-backend\"; the other makes a connection for SSH tunneling</p> <p>VSCode users may also try its support for \"port forwarding\". https://code.visualstudio.com/docs/remote/ssh#_forwarding-a-port-creating-ssh-tunnel</p> <p>Tips: if vtune-backend is restarted and your local browser shows no content, try to rebuild the SSH tunnel. </p> <p>Next, fire your local browser and paste the above URL (e.g. https://127.0.0.1:38881)</p> <p>If you access the VTune webUI for the first time, you will see a prompt to input a passphrase. Insert any passphrase as you want. </p> <p>If you are successfully connected then you should see something like this: </p> <p>Click to open a trace: </p> <p></p>"},{"location":"vtune/#extra-info-itt-api-for-tracemarker-instrumentation","title":"Extra info: ITT API for tracemarker instrumentation","text":"<p>To visualize how workers have grabbed parts to work on, we can lightly instrument our source with VTune's ITT API. The API allows us to programmatically add markers to the VTune timeline. </p> <p>This is used in exp2 for visualizing stragglers. </p> <p>To learn the use of API by example, search for \"USE_VTUNE\" in the project source code provided to you.</p> <p>Changelog</p> <p>2/8/2024: update to use vtune-backend and browser </p>"},{"location":"archived/exp1-assignment/","title":"Races and Synchronization","text":"<p>cs4414/6456 students: this is just a sample. Please refer to the official assignment.</p> <p>NOTE: this experiment should be finished on the granger1 server. NOT labsrv06 which many of you use in project 1!</p>"},{"location":"archived/exp1-assignment/#short-qa-10","title":"Short Q&amp;A (10%)","text":"<ul> <li>How many threads that can run simultaneously (i.e. thread-level parallelism offered by CPU hardware) on the lab server? If you are using a different machine, state it. </li> <li>What does pthread_join() do in the given code? </li> <li>Why concurrent, unsynchronized updates to <code>the_counter</code> leads to program errors? </li> <li>The given counter.c invokes <code>atexit()</code>. What does the function do? </li> </ul>"},{"location":"archived/exp1-assignment/#1-zoom-in-the-scene-of-race-condition-20","title":"1. Zoom in the scene of race condition (20%)","text":"<p>Here is the assembly of function <code>add(long long *pointer, long long value)</code>, as dumped from objdump. Note that without assuming x86 knowledge from you, I showed the ARMv8 version below (compiled with -O2). </p> <pre><code>640 0000000000001600 &lt;add&gt;:\n641     long long sum = *pointer + value;\n642        f9400002    ldr x2, [x0]\n643        8b010041    add x1, x2, x1\n644     *pointer = sum;\n645        f9000001    str x1, [x0]\n646 }\n647        d65f03c0    ret\n</code></pre> <p>Read the assembly and answer: </p> <p>i) How many bits in a <code>long long</code> type of integer? </p> <p>ii) Point out which instructions (by their line numbers above) constitute the window for race condition. </p> <p>iii) Will race condition still exist, if we run the program with multiple threads but on a single-core machine?</p>"},{"location":"archived/exp1-assignment/#2-use-spinlock-cas-30","title":"2. Use spinlock &amp; CAS (30%)","text":"<p>Add the following mechanisms to the source code: </p> <ul> <li>one that protects the add by a spin-lock, enabled by a --sync=s option. You will have to implement your own spin-lock operation. </li> <li>one that performs the add using compare-and-swap (CAS) primitives to ensure atomic updates to the shared counter, enabled by a --sync=c option. Note the name: compare-and-swap is the same as compare-and-exchange. </li> </ul> <p>The provided code can already parse these new options! :wink:</p>"},{"location":"archived/exp1-assignment/#example-output","title":"Example output","text":"<p>Before (by the give code)</p> <pre><code>$./counter --iterations=10000 --threads=10 --sync=s\ntest=add-s threadNum=10 iterations=10000 numOperation=200000 runTime(ns)=5640178 avgTime(ns)=28 count=-10113\n$./counter --iterations=10000 --threads=10 --sync=c\ntest=add-c threadNum=10 iterations=10000 numOperation=200000 runTime(ns)=4469589 avgTime(ns)=22 count=-7513\n</code></pre> <p>After (expected from your code). With with spinlocks and CAS, the final count value is integral, i.e. ==0. </p> <pre><code>$./counter --iterations=10000 --threads=10 --sync=s\ntest=add-s threadNum=10 iterations=10000 numOperation=200000 runTime(ns)=27917650 avgTime(ns)=139 count=0\n$./counter --iterations=10000 --threads=10 --sync=c\ntest=add-c threadNum=10 iterations=10000 numOperation=200000 runTime(ns)=20609670 avgTime(ns)=103 count=0\n</code></pre> <p>Implementation hints: both spinlock and CAS shall be implemented using the GCC's atomic built-ins. Since the built-ins are architecture-independent, you do not have to write any assembly. </p> <ul> <li> <p>The documentation can be found here. Some related discussion. </p> </li> <li> <p>Useful functions include  <code>__atomic_compare_exchange_n()</code> and <code>__atomic_store_n()</code></p> </li> <li>These functions require memory order, for which you may specific <code>__ATOMIC_SEQ_CST</code>.  (Q: could other memory order work?)</li> <li>Note: older GCC offers <code>__sync_XXX</code> built-ins, which are still supported today for backward compatibility. Avoid them. They are deprecated by the __atomic builtins. </li> </ul> <p>Search for \"todo\" in the given source code for extra hints. </p>"},{"location":"archived/exp1-assignment/#deliverable","title":"Deliverable:","text":"<p>[upload a standalone tarball named as p2-1-2.tar.gz] </p>"},{"location":"archived/exp1-assignment/#3-measure-slowdown-caused-by-synchronization-40","title":"3. Measure slowdown caused by synchronization (40%)","text":"<p>Compare the times taken for parallel updating the shared counter: </p> <ul> <li> <p>Without any synchronization</p> </li> <li> <p>With mutex (--sync=m)</p> </li> <li> <p>With spinlock (--sync=s)</p> </li> <li> <p>With CAS (--sync=c)</p> </li> </ul> <p>Report the performance with the following arguments. Write a small paragraph to explain your observation. How many repeated runs did you execute? How do you ensure your executions was unaffected by other students who may run the experiments at the same time? Would different thread counts and iteration counts affect your observation? </p> <pre><code>./counter --iterations=100000 --threads=10 --sync=m\n./counter --iterations=100000 --threads=10 --sync=s\n./counter --iterations=100000 --threads=10 --sync=c\n</code></pre>"},{"location":"archived/exp2-assignment/","title":"Scalability assignment","text":"<p>cs4414/6456 students: this is just a sample. Please refer to the official assignment. </p>"},{"location":"archived/exp2-assignment/#0-reproduce-the-benchmarks","title":"0. Reproduce the benchmarks","text":"<p>Repeat what has been described in our writeup. </p> <ul> <li>Attach a scalability plot (ONLY the one showing all the program versions) you generated. </li> <li>Compare your observation with the given results. What are the same? What are different? </li> <li>Provide explanation / reasoning</li> </ul>"},{"location":"archived/exp2-assignment/#1-the-unfinished-scalability-quest","title":"1. The unfinished scalability quest","text":"<p>How does the program scale to more than 8 cores? </p> <ul> <li>Attach a scalability plot (ONLY the one showing all the program versions) with core count = {1 2 4 6 8 10 12 16 20}. You need to tweak <code>run.sh</code> and <code>plot.py</code></li> <li>Describe your observation. </li> <li>If there's any scalability bottleneck, profile its execution with VTune (e.g. consider trying VTune's \"microarchitecture exploration\"). Can you make the program scale better? If so, show your code and profiling results; if not, reason about about possible bottlenecks. </li> </ul>"},{"location":"archived/exp2-assignment/#2-a-scalable-hashtable","title":"2. A scalable hashtable","text":""},{"location":"archived/exp2-assignment/#summary","title":"Summary","text":"<p>Take an existing hashtable implementation in <code>glib</code> and make it scalable. </p> <p><code>glib</code> is a widely used C library that implements common data structures, such as linked lists, trees, and hashtables. </p> <ul> <li>The glib hashtable API is described here. </li> <li>For example usage of the API, see the glib's test code here. </li> </ul> <p>Goal: write a benchmark program that spawn multiple threads for inserting keys to a hashtable concurrently. </p> <p>At the end of the benchmark, validate the correctness by checking all the keys in the hashtable, e.g. no missing or surplus keys. </p>"},{"location":"archived/exp2-assignment/#idea-a-hashtable-with-internal-partitions","title":"Idea - a hashtable with internal partitions","text":"<p>The \"big lock\" approach ensures correctness but cannot scale. We can build our own hashtable (called \"bigtable\") by wrapping around the glib's hashtable. A bigtable consists of N hashtables internally, where N is a parameter much larger than the number of threads. Each hashtable has its own lock which must be grabbed by a worker thread before inserting keys in the hashtable. </p> <p>To insert a key K, a worker thread first computes a hash function H(K) to determine which of the N hashtable the key should go. Then the worker thread grabs the lock for the hashtable, does the insertion, and unlock. Since N&gt;&gt;numThreads, the chance lock contention is low and our bigtable should scale better than the \"big lock\" approach. </p> <p>Of course, there are many details to take care of. I hope the tutorial above can give some useful pointers. </p>"},{"location":"archived/exp2-assignment/#a-sample-implementation-plan","title":"A sample implementation plan","text":"<ol> <li>Single-threaded. write the benchmark program using the glib hashtable API. Make sure you understand how to operate the hashtable. </li> <li>Multi-threaded with a big lock. Transform the above version by adding pthread, mutex, etc. Design test to validate the correctness of the resultant hashtable. </li> <li>Add internal partitions. </li> <li>Test &amp; profile. </li> </ol>"},{"location":"archived/vtune-sp2023/","title":"Using Intel VTune, the modern x86 profiler","text":"<p>This page describes VTune setup relevant to our experiments. It contains pointers to various information. </p>"},{"location":"archived/vtune-sp2023/#why-vtune","title":"Why VTune","text":"<p>For performance debugging like this, our \"roll-it-your-own\" manual code instrumentation can be too rudimentary. Modern profiler has been a crucial tool. In short, programmer launches a tool (\"profiler\") which in turns launches the target program being profiled. The profiler collects key information about target program execution. </p> <p>Over the past decade, profiling has seen tremendous improvement, evolving from software-based instrumentation to hardware-assisted sampling. Today, profilers can provide rich information at low overhead. </p> <p>Availability: Intel used to charge a few thousand $$ for a VTune license. Now it's freely downloadable. </p> <p>Aside: Arm's profiler is called DS-5. </p>"},{"location":"archived/vtune-sp2023/#naming","title":"Naming","text":"<p>VTune is Intel's profiler. Prior to 2018 it was called Intel \"VTune Amplifier\" (a marketing term). There are still some old documents online with the latter name. Many of the current VTune executables are still named with the \"amplxe-\" prefix. Today it is called \"oneAPI VTune\". Intel likes to tinker with marketing terms.</p>"},{"location":"archived/vtune-sp2023/#useful-vtune-documents","title":"Useful VTune documents","text":"<p>VTune's front page feature short articles &amp; videos. Recommended readings: </p> <ul> <li>A quick introduction. This video (7 min)</li> <li>A case study on profiling Linux program. This video (4.5min)</li> <li>About CPU instruction pipeline: this video and this article . A good refresher on CPU architecture and for understanding architecture profiling results. </li> </ul> <p>There are more and you may skim them.</p> <p>The official user guide is here. It's long and you do NOT have to read from back to end. Just make sure when you Google/Bing (e.g. \"vtune threading profiling\"), only pick results coming from this user guide. </p>"},{"location":"archived/vtune-sp2023/#setup","title":"Setup","text":"<p>In our experiments, we run and profile our program on the target machine and view profile results on the viewer machine. </p> <p>VTune version info: </p> Profiler version Installation package vtune_profiler_2020.2.0.610396 vtune_profiler_2020_update2.tar.gz <p>VTune has to be installed both machines.</p> <p>Machine 1: Viewer: Your own computer. Can be Windows/Linux. (Mac has some issues. See below)</p> <p>Download installation packages to your local machine:</p> <ul> <li>Method 1 (recommended): download from Collab-&gt;resources-&gt;vtune</li> <li>Method 2: <code>scp portal.cs.virginia.edu:/u/xl6yq/cs4414/VTune_Profiler_2020_update2_setup.exe .</code>  (mac/Linux users should download dmg/tar.gz)</li> <li>Method 3 (Win only): WinSCP, which can download files over SSH     </li> </ul> <p>Available packages: </p> <pre><code>\u251c\u2500\u2500 vtune_profiler_2020_update2.dmg         (for Mac)\n\u251c\u2500\u2500 m_oneapi_vtune_p_2022.2.0.172.dmg       (for Mac)\n\u251c\u2500\u2500 VTune_Profiler_2020_update2_setup.exe   (for Windows)\n\u2514\u2500\u2500 vtune_profiler_2020_update2.tar.gz      (for Linux)\n</code></pre> <ul> <li> <p>Windows users: It should just work. If you have issues installing the package, try the compatibility mode (right click the .exe -&gt; Troubleshoot compatibility). If you have an AMD machine, VTune should work too (verified on: Ryzen 7 5800x, Windows 10 21H2, VTune 2020 Update2).</p> </li> <li> <p>Linux users: if the provided .tar.gz does not work, try the newest one from Intel. </p> </li> <li> <p>Mac users: if you have an M1/M2 Mac, skip to \"last resort\" below. If you have an Intel Mac: try vtune_profiler_2020_update2.dmg first; if that crahes, try m_oneapi_vtune_p_2022.2.0.172.dmg which reportedly works on &gt; Monterey 12.3 (e.g. verified to work on a Macbook 2017 (MacOS 12.6) with Intel i7); if that does not work, try the newest one from the Intel website; if no luck, skip to \"last resort\" below. </p> </li> <li> <p>Last resort:  Students may run the VTune viewer from the command line on granger1/2. Limitations apply. See here. </p> </li> </ul> <p>The newest VTune from Intel.  </p> <p>Machine 2: Target: A multicore Linux machine, e.g. our course server. We will call VTune from command lines to collect trace. </p> <p>We recommend most students to use the course server as target. </p> <p>Notes below are ONLY for students who want to use own Linux machine as the target. </p> <p>Install VTune to: <code>/opt/intel/vtune_profiler</code></p> <p>Relaxing OS security </p> <pre><code># add to /etc/sysctl.conf\nkernel.perf_event_paranoid=1\nkernel.kptr_restrict=0\n</code></pre> <p>Make it effective</p> <pre><code>sudo sysctl -p   \n</code></pre> <ul> <li>Must have modern Intel processors (Broadwell, Haswell or even newer). Cannot be AMD. FYI: granger1/2: Ubuntu 20.04 LTS on 2x Xeon 2630v4 Broadwell (10c20t), 20 cores.</li> <li>Preferred: Ubuntu 20.04 LTS with Linux kernel &gt; 4.17. Some VTune event-based sampling features depends on it. </li> </ul>"},{"location":"archived/vtune-sp2023/#workflow-choose-one-mode-that-suits-you","title":"Workflow: choose one mode that suits you","text":"<p>Mode 1 (recommended) -- develop on the server, view results locally: develop code on the server (via SSH terminals, VS code, mounted network filesystem, etc.). In this case, target &amp; dev machines are the same. </p> <ul> <li> <p>Write code -&gt; build binary -&gt; (test to make sure it works correctly) -&gt; profile the program with VTune the server </p> </li> <li> <p>Download the profile results to your local machine (the viewer machine). This can be done from VSCode (or rsync, scp, ...)</p> </li> <li> <p>Note: this does NOT mean using your local VTune to connect to the server </p> </li> </ul> <p></p> <ul> <li>View the results on your local VTune. </li> </ul> <p>To associate execution hotspots with source lines or assembly (see below for an example), the local VTune needs the program source code &amp; binary (which must be build with symbols and debugging information). You will have to fetch them from the server to your local machine after every source modification &amp; rebuild. Consider automating this process with your script (e.g. rsync) </p> <p></p> <p>Mode 2 (if you so choose) -- develop on a personal Linux box:  develop &amp; build code on your local Linux machine; execute on the server for profiling. </p> <p>The workflow is similar to setup 1. A few things to note though: </p> <ul> <li>Since we build programs locally and execute on the server, there may be issues due to library version mismatch, etc. It worked fine for me (local machine: Ubuntu 18.04 LTS on Intel i5). A nice side effect, however, is that you no longer need to fetch source &amp; binaries from the server for the local VTune to access. </li> <li>The path for ITT library. To use VTune's ITT tracing API, e.g. for adding task markers, you will have to include C headers &amp; link to the ITT libraries. They ship with the VTune installation. Make sure you point to the right path in building, e.g. by changing CMakeList.txt. </li> <li>Be aware of local profiling results. If you try profiling on your local machine, the results may appear different than that on the target machine. Sometimes the difference may be confusing. </li> </ul> <p>Instructor's pick (FYI). It's a variant of mode 2. A bit complicated but works well for me. Locally I have a Windows machine (as the viewer) and a Linux machine (the dev machine) connected via GbE. They share a network filesystem (Samba). From the Windows machine I connect into the Linux machine (dev) via the terminal emulator of WSL2. I develop and briefly test program on the dev machine and rsync it to the server (target) for profiling. Then I rsync the profiling results to local (viewer) for viewing. </p>"},{"location":"archived/vtune-sp2023/#trace-collection","title":"Trace collection","text":"<p>On the target machine (e.g. granger1/2): </p>"},{"location":"archived/vtune-sp2023/#path-setup-do-this-every-time-you-login-to-the-target","title":"Path setup (do this every time you login to the target)","text":"<pre><code>source /opt/intel/vtune_profiler/vtune-vars.sh\nexport INTEL_LIBITTNOTIFY64=/opt/intel/vtune_profiler/lib64/runtime/libittnotify_collector.so\n</code></pre> <p>Reference </p> <p>To automate, consider appending the above to your <code>~/.bashrc</code> on the target. </p>"},{"location":"archived/vtune-sp2023/#example-commands-to-execute-for-each-collection","title":"Example commands, to execute for each collection","text":"<pre><code># hotspot analysis\nvtune -collect hotspot -knob sampling-mode=hw ./myprogram\n\n# threading analysis\nvtune -collect threading -knob sampling-and-waits=hw ./myprogram\n\n# microarchitecture analysis\nvtune -collect uarch-exploration ./myprogram\n\n# For instance ...\nvtune -collect hotspot -knob sampling-mode=hw ./list-p --iterations=1M --threads=1 --parts=1\n</code></pre> <p>(I found <code>-collect hotspot</code> is the same as <code>-collect hotspots</code>)</p>"},{"location":"archived/vtune-sp2023/#profiling-results","title":"Profiling results","text":"<p>Will be stored in a subdirectory named as, e.g. \"r000tr/\", \"r014ue/\", \"r027hs/\". </p> <p>The numbers are assigned by VTune in an ascending manner. The last two letters are the analysis type. tr-\"threading\", ue-\"microarchitecture exploration\", \"hs\"-hotspot. </p> <p>Fetch the whole subdirectory to the viewer machine. On the viewer, open the directory using the VTune installation. </p>"},{"location":"archived/vtune-sp2023/#itt-api-for-tracemarker-instrumentation","title":"ITT API for tracemarker instrumentation","text":"<p>To visualize how workers have grabbed parts to work on, we can lightly instrument our source with VTune's ITT API. The API allows us to programmatically add markers to the VTune timeline. </p> <p>This is used in exp2 for visualizing stragglers. </p> <p>To learn the use of API by example, search for \"USE_VTUNE\" in the project source code provided to you.</p>"},{"location":"archived/vtune-sp2023/#what-to-do-now","title":"What to do now","text":"<p>Set up VTune with your local machine and test the whole workflow with a simple program. </p>"}]}